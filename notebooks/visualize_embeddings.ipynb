{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(op.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abeae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8bcf2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a045ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import LinearColorMapper, ColumnDataSource\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from datasets import SLREmbeddingDataset, collate_fn_padd\n",
    "from datasets.dataset_loader import LocalDatasetLoader\n",
    "from models import embeddings_scatter_plot_splits\n",
    "from models import SPOTER_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82766a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_FOLDER = '../data/'\n",
    "os.environ[\"BASE_DATA_FOLDER\"] = BASE_DATA_FOLDER\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead15a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL FROM CLEARML\n",
    "# from clearml import InputModel\n",
    "# model = InputModel(model_id='9fddb0d4389a4cdb867acada859a6b64')\n",
    "# checkpoint = torch.load(model.get_weights())\n",
    "\n",
    "\n",
    "CHECKPOINT_PATH = \"../checkpoints/checkpoint_embed_992.pth\"\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "\n",
    "model = SPOTER_EMBEDDINGS(\n",
    "    features=checkpoint[\"config_args\"].vector_length,\n",
    "    hidden_dim=checkpoint[\"config_args\"].hidden_dim,\n",
    "    norm_emb=checkpoint[\"config_args\"].normalize_embeddings,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_DATASET = 'wlasl'  # or 'lsa'\n",
    "if SL_DATASET == 'wlasl':\n",
    "    dataset_name = \"wlasl_mapped_mediapipe_only_landmarks_25fps\"\n",
    "    num_classes = 100\n",
    "    split_dataset_path = \"WLASL100_{}_25fps.csv\"\n",
    "else:\n",
    "    dataset_name = \"lsa64_mapped_mediapipe_only_landmarks_25fps\"\n",
    "    num_classes = 64\n",
    "    split_dataset_path = \"LSA64_{}.csv\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758716b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_loader(loader_name=None):\n",
    "    if loader_name == 'CLEARML':\n",
    "        from datasets.clearml_dataset_loader import ClearMLDatasetLoader\n",
    "        return ClearMLDatasetLoader()\n",
    "    else:\n",
    "        return LocalDatasetLoader()\n",
    "\n",
    "dataset_loader = get_dataset_loader()\n",
    "dataset_project = \"Sign Language Recognition\"\n",
    "batch_size = 1\n",
    "dataset_folder = dataset_loader.get_dataset_folder(dataset_project, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1527959",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "splits = ['train', 'val']\n",
    "dfs = {}\n",
    "for split in splits:\n",
    "    split_set_path = op.join(dataset_folder, split_dataset_path.format(split))\n",
    "    split_set = SLREmbeddingDataset(split_set_path, triplet=False)\n",
    "    data_loader = DataLoader(\n",
    "        split_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn_padd,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        num_workers=multiprocessing.cpu_count()\n",
    "    )\n",
    "    dataloaders[split] = data_loader\n",
    "    dfs[split] =  pd.read_csv(split_set_path)\n",
    "\n",
    "with open(op.join(dataset_folder, 'id_to_label.json')) as fid:\n",
    "    id_to_label = json.load(fid)\n",
    "id_to_label = {int(key): value for key, value in id_to_label.items()}\n",
    "\n",
    "tsne_results, labels_results = embeddings_scatter_plot_splits(model,\n",
    "                                                              dataloaders,\n",
    "                                                              device,\n",
    "                                                              id_to_label,\n",
    "                                                              perplexity=40,\n",
    "                                                              n_iter=1000)\n",
    "\n",
    "\n",
    "set_labels = list(set(next(chain(labels_results.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3af5bf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for split in splits:\n",
    "    split_set_path = op.join(dataset_folder, split_dataset_path.format(split))\n",
    "    df =  pd.read_csv(split_set_path)\n",
    "    df['tsne_x'] = tsne_results[split][:, 0]\n",
    "    df['tsne_y'] = tsne_results[split][:, 1]\n",
    "    df['split'] = split\n",
    "    if SL_DATASET == 'wlasl':\n",
    "        df['video_fn'] = df['video_id'].apply(lambda video_id: os.path.join(BASE_DATA_FOLDER, f'wlasl/videos/{video_id:05d}.mp4'))\n",
    "    else:\n",
    "        df['video_fn'] = df['video_id'].apply(lambda video_id: os.path.join(BASE_DATA_FOLDER, f'lsa/videos/{video_id}.mp4'))\n",
    "    dfs[split] = df\n",
    "\n",
    "df = pd.concat([dfs['train'].sample(100), dfs['val']]).reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def load_videos(video_list):\n",
    "    print('loading videos')\n",
    "    videos = []\n",
    "    for video_fn in tqdm(video_list):\n",
    "        if video_fn is None:\n",
    "            video_data = None\n",
    "        else:\n",
    "            with open(video_fn, 'rb') as fid:\n",
    "                video_data = base64.b64encode(fid.read()).decode()\n",
    "        videos.append(video_data)\n",
    "    print('Done loading videos')\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904298f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_img_div = False\n",
    "if use_img_div:\n",
    "    # sample dataframe data to avoid overloading scatter plot with too many videos\n",
    "    df = df.sample(frac=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42832f7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "img_div = '''\n",
    "        <div>\n",
    "            <img\n",
    "                src=\"data:video/mp4;base64,@videos\" height=\"90\" alt=\"@videos\" width=\"120\"\n",
    "                style=\"float: left; margin: 0px 15px 15px 0px;\"\n",
    "                border=\"2\"\n",
    "            ></img>\n",
    "        </div>\n",
    "'''\n",
    "TOOLTIPS = f\"\"\"\n",
    "    <div>\n",
    "        {img_div if use_img_div else ''}\n",
    "        <div>\n",
    "            <span style=\"font-size: 17px; font-weight: bold;\">@label_desc - @split</span>\n",
    "            <span style=\"font-size: 15px; color: #966;\">[$index]</span>\n",
    "        </div>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "cmap = LinearColorMapper(palette=\"Turbo256\", low=0, high=len(set_labels))\n",
    "\n",
    "output_notebook()\n",
    "# or \n",
    "# output_file(\"scatter_plot.html\")\n",
    "\n",
    "p = figure(width=1000,\n",
    "           height=800,\n",
    "           tooltips=TOOLTIPS,\n",
    "           title=f\"Check {'video' if use_img_div else 'label'} by hovering mouse over the dots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4daf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_data = dict(\n",
    "    x=df['tsne_x'],\n",
    "    y=df['tsne_y'],\n",
    "    label=df['labels'],\n",
    "    label_desc=df['label_name'],\n",
    "    split=df['split']\n",
    ")\n",
    "\n",
    "if use_img_div:\n",
    "    emb_videos = load_videos(df['video_fn'])\n",
    "    column_data[\"videos\"] = emb_videos\n",
    "\n",
    "source = ColumnDataSource(data=column_data)\n",
    "\n",
    "p.scatter('x', 'y',\n",
    "     size=10,\n",
    "     source=source,\n",
    "     fill_color={\"field\": 'label', \"transform\": cmap},\n",
    "     line_color={\"field\": 'label', \"transform\": cmap},         \n",
    "     #legend_label={\"field\": 'split', \"transform\": lambda x: df['split']},\n",
    "#      marker={\"field\": 'split'}\n",
    "         )\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d761766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73f195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
