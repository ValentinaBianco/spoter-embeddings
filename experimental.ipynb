{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bbbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98325ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Task, Logger, Dataset\n",
    "import os\n",
    "import os.path as op\n",
    "import argparse\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import __balance_val_split, __split_of_train_sequence, __log_class_statistics\n",
    "from datasets import CzechSLRDataset, SLREmbeddingDataset, collate_fn_triplet_padd, collate_fn_padd\n",
    "from spoter import SPOTER, SPOTER_EMBEDDINGS, train_epoch, evaluate, evaluate_top_k, train_epoch_embedding, \\\n",
    "                    evaluate_embedding, embeddings_scatter_plot, GaussianNoise, BatchAllTripletLoss, \\\n",
    "                    train_epoch_embedding_online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f745b8",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285e0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"embedding_scheduler_test\"\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "dataset_project = \"Sign Language Recognition\"\n",
    "dataset_name = \"wlasl\"\n",
    "training_set_path = \"WLASL100_train_25fps.csv\"\n",
    "validation_set_path = \"WLASL100_val_25fps.csv\"\n",
    "embedding_model = 1\n",
    "vector_length = 32\n",
    "epoch_iters = 100\n",
    "scheduler_factor = 0.5\n",
    "num_classes = 100\n",
    "hidden_dim = 108\n",
    "batch_size = 25\n",
    "hard_triplet_mining = \"in_batch\"\n",
    "\n",
    "gaussian_mean = 0\n",
    "gaussian_std = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f91910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b98356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPOTER_EMBEDDINGS(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): SPOTERTransformerDecoderLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): SPOTERTransformerDecoderLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): SPOTERTransformerDecoderLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): SPOTERTransformerDecoderLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): SPOTERTransformerDecoderLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): SPOTERTransformerDecoderLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=108, out_features=108, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=108, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=108, bias=True)\n",
       "          (norm1): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_embed): Linear(in_features=108, out_features=32, bias=True)\n",
       "  (output): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slrt_model = SPOTER_EMBEDDINGS(features=vector_length, hidden_dim=hidden_dim)\n",
    "model_type = 'embed'\n",
    "slrt_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60af8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cel_criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "cel_criterion = BatchAllTripletLoss(device, margin=1, filter_easy_triplets=False)\n",
    "sgd_optimizer = optim.SGD(slrt_model.parameters(), lr=lr)\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "587e74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "transform = transforms.Compose([GaussianNoise(gaussian_mean, gaussian_std)])\n",
    "dataset_folder = Dataset.get(dataset_project=dataset_project, dataset_name=dataset_name).get_local_copy()\n",
    "training_set_path = op.join(dataset_folder, training_set_path)\n",
    "\n",
    "train_val_set = SLREmbeddingDataset(training_set_path, triplet=False)\n",
    "# Train dataloader for validation\n",
    "train_val_loader = DataLoader(\n",
    "    train_val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn_padd,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    num_workers=multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "train_set = SLREmbeddingDataset(\n",
    "    training_set_path,\n",
    "    triplet=False,\n",
    "    transform=transform,\n",
    "    augmentations=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_padd,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    num_workers=multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "validation_set_path = op.join(dataset_folder, validation_set_path)\n",
    "val_set = SLREmbeddingDataset(validation_set_path, triplet=False)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn_padd,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    num_workers=multiprocessing.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996e57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, val_acc = 0, 0\n",
    "losses, train_accs, val_accs = [], [], []\n",
    "lr_progress = []\n",
    "top_val_acc = -999\n",
    "top_model_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a61931f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.8892873308875344\n",
      "valid triplets 92\n",
      "num positive losses 92\n",
      "val acc -0.42441365122795105\n",
      "train acc -0.3172035217285156\n",
      "train loss 0.9172803922133013\n",
      "valid triplets 138\n",
      "num positive losses 138\n",
      "val acc -0.432142972946167\n",
      "train acc -0.3174569606781006\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    slrt_model.train(True)\n",
    "    train_loss, val_silhouette_coef, valid_triplets, used_triplets = train_epoch_embedding_online(\n",
    "        slrt_model,\n",
    "        10,\n",
    "        hard_triplet_mining,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        cel_criterion,\n",
    "        sgd_optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "    )\n",
    "    print(f\"train loss {train_loss}\")\n",
    "    print(f\"valid triplets {valid_triplets}\")\n",
    "    print(f\"num positive losses {num_positive_losses}\")\n",
    "    \n",
    "    print(f\"val acc {val_silhouette_coef}\")\n",
    "    \n",
    "    \n",
    "    slrt_model.train(False)\n",
    "    # calculate acc on train dataset\n",
    "    silhouette_coefficient_train = evaluate_embedding(slrt_model, train_val_loader, device)\n",
    "    print(f\"train acc {silhouette_coefficient_train}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe475fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rompe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_482/3919362396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrompe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rompe' is not defined"
     ]
    }
   ],
   "source": [
    "print(rompe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results, labels = embeddings_scatter_plot(slrt_model, val_loader, device, perplexity=40, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    x=tsne_results[:, 0],\n",
    "    y=tsne_results[:, 1]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f2eb7",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"no_rotation\"  # Name of the experiment after which the logs and plots will be named\n",
    "num_classes = 100  # Number of classes to be recognized by the model\")\n",
    "hidden_dim = 108  # Hidden dimension of the underlying Transformer model\n",
    "seed = 379  # Seed with which to initialize all the random components of the training\n",
    "dataset_name = \"wlasl\"\n",
    "dataset_project = \"Sign Language Recognition\"\n",
    "testing_set_path = \"WLASL100_val_25fps.csv\"  # Path to the testing dataset CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all the random seeds\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "# Set device to CUDA only if applicable\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f37a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "slrt_model = SPOTER(num_classes=num_classes, hidden_dim=hidden_dim)\n",
    "slrt_model.train(False)\n",
    "slrt_model.to(device)\n",
    "\n",
    "# Construct the other modules\n",
    "cel_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3161103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set\n",
    "dataset_folder = Dataset.get(dataset_project=dataset_project, dataset_name=dataset_name).get_local_copy()\n",
    "testing_set_path = op.join(dataset_folder, testing_set_path)\n",
    "\n",
    "eval_set = CzechSLRDataset(testing_set_path)\n",
    "eval_loader = DataLoader(eval_set, generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f61bf",
   "metadata": {},
   "source": [
    "# Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_result, top_result_name = 0, \"\"\n",
    "checkpoints_filenames = os.listdir(\"out-checkpoints/\" + experiment_name)\n",
    "\n",
    "for checkpoint_filename in sorted(checkpoints_filenames):\n",
    "    tested_model = torch.load(\"out-checkpoints/\" + experiment_name + '/' + checkpoint_filename)\n",
    "    _, _, eval_acc = evaluate(tested_model, eval_loader, device, print_stats=False)\n",
    "\n",
    "    if eval_acc > top_result:\n",
    "        top_result = eval_acc\n",
    "        top_result_name = experiment_name + '/' + checkpoint_filename\n",
    "\n",
    "    print(checkpoint_filename + \"  ->  \" + str(eval_acc))\n",
    "\n",
    "print(\"\\n\" \"Best checkpoint: \" + top_result_name + \", acc: \" + str(top_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25aff0d",
   "metadata": {},
   "source": [
    "# Accuracy in top k predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Accepted ranking with specified model\n",
    "best_model_path = \"out-checkpoints/no_rotation/checkpoint_v_14.pth\"  # Best model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22885378",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model = torch.load(best_model_path)\n",
    "_, _, eval_acc = evaluate(tested_model, eval_loader, device, print_stats=False)\n",
    "_, _, eval_acc_k = evaluate_top_k(tested_model, eval_loader, device, k=k)\n",
    "\n",
    "print(f'Acc k=1: {best_model_path} ->  {str(eval_acc)}')\n",
    "print(f'Acc k={k}: {best_model_path} ->  {str(eval_acc_k)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4d6a4",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374852ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model = torch.load(best_model_path)\n",
    "\n",
    "inputs, labels = next(iter(eval_loader))\n",
    "inputs = inputs.squeeze(0).to(device)\n",
    "print(inputs.shape)\n",
    "\n",
    "labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "outputs = tested_model(inputs).expand(1, -1, -1)\n",
    "print(outputs)\n",
    "loss = cel_criterion(outputs[0], labels[0]).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
